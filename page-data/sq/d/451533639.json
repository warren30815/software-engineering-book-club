{"data":{"allMdx":{"nodes":[{"fields":{"slug":"/","title":"software-engineering-book-club"},"frontmatter":{"draft":false},"rawBody":"# software-engineering-book-club\n\n## Github pages (Big shout-out to [@ninebird2](https://github.com/ninebird2) for deploying the repo to GitHub Pages!)\n\n<https://warren30815.github.io/software-engineering-book-club/>\n\n## Agenda\n\n[System Design]: ./content/system-design/system-design-interview-alex-xu-volume1/README.md\n[DDD]: ./content/domain-driven-design/domain-modeling-made-functional/README.md\n[Micro Frontend]: ./content/front-end/micro-frontend/README.md\n\n| Date  | Speaker            | Topic               |\n|-------|--------------------|---------------------|\n| 07/07 | Jordan             | [System Design] CH7 |\n| 07/14 | 雷 N               | [System Design] CH6 |\n| 07/21 | 竹子               | [Micro Frontend]    |\n| 07/28 | Jordan             | [System Design] CH8 |\n| 08/04 | Jay / Fienna Liang | [DDD]               |\n\n## Book list\n\nSee content/ folder, including system-design / front-end / domain-driven-design (DDD)... fields.\n"},{"fields":{"slug":"/content/domain-driven-design/domain-modeling-made-functional/","title":"Domain-Modeling-Made-Functional"},"frontmatter":{"draft":false},"rawBody":"English Book on Amazon: [Domain Modeling Made Functional: Tackle Software Complexity with Domain-Driven Design and F# ](https://www.amazon.com/Domain-Modeling-Made-Functional-Domain-Driven/dp/1680502549)\n\n| Chapter                                    | Speaker            | Completed |\n| ------------------------------------------ | ------------------ | --------- |\n| 1. Introducing Domain Driven Design        | Jay / Fienna Liang | ✔️         |\n| 2. Understanding the Domain                |                    | ✔️         |\n| 3. A Functional Architecture               |                    | ✔️         |\n| 4. Understanding Types                     |                    | ✔️         |\n| 5. Domain Modeling with Types              |                    | ✔️         |\n| 6. Integrity and Consistency in the Domain |                    | ✔️         |\n| 7. Modeling Workflows as Pipelines         |                    | ✔️         |\n| 8. Understanding Functions                 |                    | ✔️         |\n| 9. Implementation: Composing a Pipeline    |                    | ✔️         |\n| 10. Implementation: Working with Errors    |                    | ✔️         |\n| 11. Serialization                          |                    | ✔️         |\n| 12. Persistence                            |                    | ✔️         |\n| 13. Evolving a Design and Keeping It Clean |                    | ✔️         |\n\n> Note: Use [Markdown table generator](https://www.tablesgenerator.com/markdown_tables) to load, modify and format the table\n"},{"fields":{"slug":"/content/front-end/micro-frontend/","title":"微前端"},"frontmatter":{"draft":false},"rawBody":"# 微前端\n\n## Defined noun\n\n- 以下均使用 微應用(Micro Application) 替代來稱呼 微前端(Micro Frontend)\n- Module： 每一個 js 檔案都是一個獨立的 Module，多個依賴去進行 import 模組也算一個 Module\n- Package: 宣告了一個 package.json 的多塊 Module 組成的大型模組\n\n## 什麼是 Micro Frontend？\n\n後端微服務來說，就是建立不同的 Service Application 由各自的團隊維護運行。每個團隊使用各自的語言、技術、框架，互不衝突，全部溝通仰賴 HTTP Request & Socket 相互溝通。\n而微前端，則是在一個 SPA (Single Page Application) 之下乘載多個來源的 UI Application 的架構。仰賴使用 Web API 來相互溝通。\n\n## 什麼應用場景需要使用 Micro Frontend？\n\n當前端團隊龐大到一個程度時會產生一些問題：\n\n### 1. 多重技術\n\n要解決的問題：\n不同產品使用不同的前端技術，無法整合\n\n採用後的效用：\n架構可以將兩個不同框架的應用整合成一個。\n\n### 2. 部署\n\n要解決的問題：\n部署要以一個 Application 為單位去打包， bundle 的時間非常久\n\n採用後的效用：\n各個應用也可以單獨部署，無須一整套捆綁在一起，這樣不管是開發還是發布都能減輕負擔\n\n### 3. HMR\n\n要解決的問題：\n架構如果是採用 Webpack 這種工具，當專案變大時，HMR(Hot Module Reload) 會非常久\n\n採用後的效用：\n當啟動應用的必要基礎模組減少變小，那啟動專案和 HMR 所需要的時間就能大幅下降。\n\n### 4. 專案龐大\n\n要解決的問題：\n專案模組巨大，耦合嚴重，單專案應用的學習成本高昂\n\n採用後的效用：\n可以更容易切分工作，能夠把不同的應用和功能切分派給布團的團隊維護。如果剛開始就採用 Micro Application 更能有意識去進行模組的共用切分。\n\n## 實作方法差異產生的優劣分析\n\n目前常見的 Micro Application 解決方案，以及實作範例，但詳細做法不在此處說明。\n\n### Iframe\n\n該方法其實很早以前就被提出，也是最單純的微應用解決方案。\n\n特點：\n\n1. 對於環境隔離性很強，不需要擔心 JS 和 CSS 相互污染。\n2. 學習成本低，容易使用。\n\n缺點：\n\n1. 幾乎無法共用 Module 或 Package，導致一但拆分會異常龐大。\n2. 資料通訊與溝通非常麻煩，幾乎只能靠 postMessage 去通訊。\n\n```jsx\nconst render = () => <iframe src=\"/apps/micro-app.html\" />;\n```\n\n### Client Side JavaScript\n\n透過動態載入 JavaScript Module 來掛載應用，也是目前微應用最主流的作法。\n\n特點：\n\n1. 主程式和為微應用的資料交互容易，也有許多模組共用的解決方案。\n2. 可以共享網頁全域事件和變數。\n\n缺點：\n\n1. 每一個微應用的 js & css 容易相互污染，更甚至會搶用同一個 `window`&`document` 的變數使用\n2. 掛載方式的實作需要關注生命週期與模組載入先後順序\n3. 在 SSR(Server Side Render) 架構下時還要額外實作 SSI\n\n```jsx\nconst mount = async (id) => {\n  const module = await import(\"/apps/micro-app\");\n  const el = document.getElementById(id);\n  const App = module.default;\n  createRoot(el).mount(<App />);\n};\n\nconst render = () => {\n  const id = \"micro-app\";\n  useEffect(() => mount(id), []);\n  return <div id={id}></div>;\n};\n```\n\n### Web Component\n\n特點：\n\n1. 可以使用 shadow dom 去隔離 css\n2. 能夠以開發 Component 為單位去拆分不同的模組，需要注入時只需要用 `customElements.define` 來註冊要追加的元件\n3. 可以不需要關心處理流程，無論先掛載元素還是先讀取 JS 註冊均不影響處理結果，也不會有錯誤發生\n4. 有 SSI 相關解決方案能一併處理 SSR 的問題\n\n缺點：\n\n1. 使用 shadow dom 會產生更多關於 JS 交互的問題，JS 也仍然會交互影響\n2. 初始化時只能取得 attribute 作為參數，無法趕在掛載前將物件參數下傳，需要再重新取出 DOM 實體去傳遞資訊\n\n```jsx\n// remote module\nimport App from \"./App\";\n\nclass MicroApp extends HTMLElement {\n  connectedCallback() {\n    const el = document.createElement(\"div\");\n    this.appendChild(el);\n    createRoot(el).mount(<App />);\n  }\n}\n\ncustomElements.define(\"micro-app\", MicroApp);\n```\n\n```jsx\nconst render = () => {\n  useEffect(() => import(\"/apps/micro-app\"), []);\n  return createElement(\"micro-app\");\n};\n```\n\n## 微前端的缺陷與問題\n\n不管如何，採用這架構背後墊高相當大成本，如果不是超大的產品真的不建議輕易採用。但如果是超大的產品，也會產生要重構並且抽離困難等問題，這就不單純是技術問題。\n\n| -                                    | Front-end monolith                   | Micro frontends                                |\n| ------------------------------------ | ------------------------------------ | ---------------------------------------------- |\n| Codebase (程式碼量)                  | 又大又笨重                           | 分成可管理的模組                               |\n| Deployment (部署)                    | 整個應用同時打包部署                 | 每個模組的獨立部署                             |\n| Feature development speed (開發速度) | 隨著時間的推移減慢                   | 初期架構開發緩慢，但小需求完成快速             |\n| Maintenance (維護)                   | 隨著時間增加更難以維護               | 每個模組維護難度低                             |\n| Stability (穩定)                     | 不足（一個小故障可能會破壞整個系統） | 高（一個組件中的故障對系統影響很小或沒有影響） |\n| Updates (更新)                       | 冗長（可能需要大量程式碼重寫）       | 可以快速推                                     |\n| Tech stack (技術線)                  | 整個系統的技術統一                   | 各個模組可能會有所不同                         |\n| Testing (測試)                       | 隨著時間的推移越難以測試             | 對於單個應用快速，但對於整個完整應用困難       |\n| Team (團隊)                          | 一個團隊維護該專案                   | 多個團隊維護該專案                             |\n| Budget (預算)                        | 取決於項目規模和復雜程度             | 需要大量前期投資                           |\n\n## 微應用實作問題解決方案\n\n在實作微應用時會遇上很多問題，每一種解決方案也都存在對應的優缺點與困難點，甚至有些就是一個大坑，直接是此路不通。因應這些問題，這裡列出各種問題與對應的解決方案。\n以下均是實際在工作上我們採用的架構做為情境來提出解決方案，以這個前提去敘述實作細節。\n\n情境描寫：\n\n- 採用 Web Component\n- 框架： Vue、React\n- 打包工具： Webpack\n\n### Package 共享\n\n問題：\n\n在微應用之中，多個不同的應用會有重複使用的 Package ，這時候就會有共享 Package 的需求。因為每個應用都有自己的打包工具，而且打包工具的版本也不一定相同，這時候就會有版本衝突的問題，而且打包工具的設定也不一定相同，這時候就會有設定衝突的問題。\n\n解決方案：\n\n基於要解決這樣的問題，目前最主流的解決方案就是 `Module Federation`，用來共用模組，還可以做到版本控管的效果。同時也要管理 tree shaking 的問題，避免打包出來的檔案過大。\n\n### CSS 處理\n\n問題：\n\n在微應用之中，CSS 的課題就是全域污染的問題。最重要的就是依據 CSS 採用的方案不同，解決方案也會有所不同。但通常最麻煩的問題是全域使用的 reset CSS & CSS variable ，這時候就會有衝突的問題。而且在微應用之中，CSS 的樣式也會有重複使用的情況，這時候就也會有共享 CSS 的需求。\n\n解決方案：\n\n- 採用 CSS in JS 的方式，這樣就不會有全域污染的問題，但是這樣的方式會有 CSS 語法的限制，而且也會有 CSS 轉換成 JS 的效能問題。\n- 採用 CSS Module 的方式，這樣就不會有全域污染的問題，但對於檔案管理上會多 CSS 相關檔案，打包相關問題比較多。\n- 採用 Atomic CSS 的方式，主軸在每一個微應用都必須遵守一樣的 CSS 規範，這樣就不會有全域污染的問題，但不適合用在技術線不一致的重構整合。\n- 採用 Shadow Dom 強制隔離，但 Shadow Dom 會有 JS 操作限制，對於 querySelector, closest, event bubbling 無法跨越 Shadow Dom。\n\n### 資料交互\n\n問題：\n\n無論整個應用怎麼拆，就是會遇上需要資料交互的需求，這時候就會有資料交互的問題。而且在微應用之中，資料交互的問題就會變得更加複雜，因為每個應用都有自己的狀態管理，這時候就會有狀態管理的問題。\n\n解決方案：\n\n- 使用 CustomEvent，透過 dispatchEvent 來進行資料交互。\n- 使用可以在 global 運作並且廣播狀態變更的狀態管理器，比如 mobx、redux 之類的函式庫。\n- 資料流的管理上會是向上層通知再向下層廣播觸發傳遞，這樣的方式會比較好管理。\n\n### 路由交互\n\n問題：\n\n網頁路由其實只有一個，但在微應用之中，每個應用都有自己的路由，這時候就會有路由交互的問題。\n\n解決方案：\n\n- 每一個框架都有自己的路由管理器，可以透過這些路由管理器來觸發全域事件廣播通知其他的路由進行路由的狀態同步。\n- 也可以乾脆採用單路由管理。\n\n### 多語言處理\n\n問題：\n\n通常每個微應用不但有自己的語系，還會有共享的語系，還可能有外部注入語系，這時候就會有多語言處理的問題。\n\n解決方案：\n\n- 採用 i18n 的方式，每一個微應用建立一個 i18n 實體，各自去管理自己的語言包，避免採用共用。如果有共用需求可以配置權重高底，以外部注入的語系為主，再來是共用語系，最後是自己的語系。\n\n### 部署架構\n\n微應用部署沒有一套標準的解決方案，因為本質就是以 JavaScript 檔案為核心。\n通常會採用的方式有以下幾種：\n\n- 將打包後的靜態黨放在後端的靜態檔案位置，這樣的方式可以避免 CDN 的成本，但是會增加後端管理的負擔。\n- 以 CDN 為主，透過 CDN 來提供檔案，或是放在 MinIO 或 S3 提供靜態檔案。\n- Docker 化，透過 Docker 來提供檔案，這樣的方式可以避免 CDN 的成本，使用 Nginx 來指向到資料位置。\n\n### SSR\n\n問題：\n\n微應用核心概念是使用 JavaScript 動態產生出檔案，但是這樣的方式對於 SEO 來說是非常不友善的，這時候就需要在 Server 完成渲染，但就有不相容問題。也不能直接採用字串渲染，依照現代 SSR 架構其實是 CSR & SSR 混合渲染，如何讓應用知道何時該用 SSR，也知道何時該 CSR。\n\n解決方案：\n\n這個會是微應用上最為麻煩的，基本上建議還是採用 CSR 的方式，但是如果有 SEO 的需求，這時候就需要透過 SSI 的方式來進行渲染。然而 SSI 相關技術目前還不是很成熟，包含 Server Component 的相關函式庫也都不夠穩定，如果還有跨框架的需求，就更加麻煩了。\n透過框架生態系提供的函式庫來進行渲染，或是可以直接用非同步方式取的字串進行截取組合，等到了 CSR 再去取渲染資源來進行渲染。\n\n### 多個 Repo 管理\n\n問題：\n\n因為微應用需要多專案多應用拆分，當要拆分成多個 Repo 管理時，要去相互取用變數、安裝、打包、部署都會比較麻煩，當 Repo 之間的控制與腳本整合就比較不容易。\n\n解決方案：\n\n可以採用 Monorepo 架構，每一個專案各自運行，但部署和共享資訊可以透過 Monorepo 來進行管理。可以使用 Lerna, Nx 等管理工具來進行管理。\n\n### 多種 Framework 管理\n\n問題：\n\n微應用的核心概念就是可以使用不同的框架，但是這樣的方式會有不同框架的相容性問題，而且也會有不同框架的打包問題。\n\n解決方案：\n\n面對不同框架的相容性問題，可以透過 Web Component 來進行管理，但是 Web Component 也會有不同框架的打包問題，這時候就需要透過打包工具來進行管理，但是打包工具也會有不同框架的相容性問題，這時候就需要透過打包工具的插件來整合。微應用與微應用盡量要避免直接傳遞組件物件，盡量使用字串來傳遞，這樣就可以避免不同框架的相容性問題。\n\n## 常見問題\n\n### 直接以 React Component 來進行拆分\n\n或許看過這樣使用 :\n\n```jsx\nconst AppFC = lazy(() => import('app/ReactComponent'))\nfunction App() {\n  return (\n    <Suspense fallback={<div>Loading...</div>}>\n      <AppFC />\n    </Suspense>\n  )\n}\n```\n\n雖然直接以 Component 來進行拆分方方便，但是這樣的方式會當跨框架使用時將無法溝通，這種方式不如採用 Package Library，還可以得到完整的 TS 型別支援，也可以減少網路損耗。而微應用要去解決的應該是業務層的拆分，而不是技術層的拆分。\n\n### 跨應用取得 JS 檔案怎麼取？\n\n應該要把共享元件的進入點封裝成 JS 檔案，而且不要在打算取得的檔案命名的地方加上哈希字串，這樣遠端才能夠預期得到的檔案名稱。或是可以建立檔案索取的路徑表，透過建立資料集查詢索取檔案的目標位置。但這些問題根本解決是需要建立一個 Proxy Server，可以用 Nginx, k8s ingress 等等方案來達到轉址取得靜態資源。不建議直接在前端進行處理，這樣會有安全性的問題。\n\n### 可以使用 Vite Module Federation？\n\n雖然網路上可以找到使用 Vite Module Federation 的範例，但是目前 Vite Module Federation 還不夠穩定，而且也沒有完整的文件，這樣的方式會讓整個專案變得非常不穩定，建議還是使用 Webpack Module Federation，實質上來講，官方也沒有給出很好的解決方案。\n萬一就是要跟 Vite 的專案進行整合，要特別注意有些套件可能發生衝突，甚至沒辦法在 development mode 進行 Module Federation 的跨應用共享。建議的做法是採用 Webpack 執行編譯輸出，隔離開發採用 Vite 運行。但一次兩套維護成本非常高，目前只期待官方能夠提供更好的解決方案，尚無較優的解決方案。\n舉例像是靜態資源路徑並未優化，要手動再去處理路徑。也沒有提供像是 webpack 有多種載入機制，目前只提供 script module 一種。\n\n### 前端變數該怎麼傳遞？\n\n大部分前端想渲染變數，直覺做法其實是在專案 env 設定，但這其實是有很大的限制。如果需要在 Docker Image 環境渲染就會無法修改，每一次修改變數就要經歷漫長的 docker build 過程。最理想是要有一個變數的靜態檔案存放在資源處，透過修改這份靜態檔案，讓重新拉取應用的對象或是直接在部署階段都可以帶入參數。這樣的方式可以避免每一次修改變數都要重新打包，也可以避免在 Docker Image 環境無法修改變數的問題。\n如果提供資源的主應用能夠採用 Client Service，更能夠動態透過伺服器去渲染變數。當然，SSR 架構的微應用更加複雜。\n\n### 要如何共享型別和函式？\n\n答案是「不要共享」，所有要共享的東西應該都包裝成 Package Library，要傳遞的狀態則是透過傳遞用的接口去接收，型別則是透過 Package Library 去得知，或是以規範文件去規定應該使用的規格。\n\n### 要如何共享靜態資源？\n\n在使用 vite 打包會遇上靜態路徑資源會吃遠端對象的問題，最好的解決方案就是使用將相關靜態資源包上 CDN。或是將所有靜態資源以 JS 的形式封裝用 JS 的方式進行載入，可以避開既有機制上的限制。\n\n## Reference\n\n- [Micro Frontends](https://leanylabs.com/blog/micro-frontends-overview/)\n- [All You Need to Know About Micro Frontends](https://micro-frontends.org/)\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/","title":"System-Design-Interview-Alex-Xu-Volume1"},"frontmatter":{"draft":false},"rawBody":"English Book: [System Design Interview – An insider's guide: Xu, Alex (Volume 1)](<https://github.com/G33kzD3n/Catalogue/blob/master/System%20Design%20Interview%20An%20Insider%E2%80%99s%20Guide%20by%20Alex%20Xu%20(z-lib.org).pdf>)\n\nChinese Translation: [內行人才知道的系統設計面試指南](https://www.books.com.tw/products/0010903454)\n\n| Chapter                                                        | Speaker            | Completed |\n| -------------------------------------------------------------- | ------------------ | --------- |\n| CHAPTER 1: SCALE FROM ZERO TO MILLIONS OF USERS                | Jay / Fienna Liang | ✅        |\n| CHAPTER 2: BACK-OF-THE-ENVELOPE ESTIMATION                     |                    | ✔️        |\n| CHAPTER 3: A FRAMEWORK FOR SYSTEM DESIGN INTERVIEWS            |                    | ✔️        |\n| CHAPTER 4: DESIGN A RATE LIMITER                               | 杯 / 雷 N          | ✅        |\n| CHAPTER 5: DESIGN CONSISTENT HASHING                           | 雷 N               | ✅        |\n| CHAPTER 6: DESIGN A KEY-VALUE STORE                            | 雷 N               | ✅        |\n| CHAPTER 7: DESIGN A UNIQUE ID GENERATOR IN DISTRIBUTED SYSTEMS | Jordan             | ✅        |\n| CHAPTER 8: DESIGN A URL SHORTENER                              | Jordan             | ✅        |\n| CHAPTER 9: DESIGN A WEB CRAWLER                                |                    | ✔️        |\n| CHAPTER 10: DESIGN A NOTIFICATION SYSTEM                       | Danny              | ✅        |\n| CHAPTER 11: DESIGN A NEWS FEED SYSTEM                          |                    | ✔️        |\n| CHAPTER 12: DESIGN A CHAT SYSTEM                               |                    | ✔️        |\n| CHAPTER 13: DESIGN A SEARCH AUTOCOMPLETE SYSTEM                |                    | ✔️        |\n| CHAPTER 14: DESIGN YOUTUBE                                     |                    | ✔️        |\n| CHAPTER 15: DESIGN GOOGLE DRIVE                                |                    | ✔️        |\n| CHAPTER 16: THE LEARNING CONTINUES                             |                    | ✔️        |\n\n> Note: Use [Markdown table generator](https://www.tablesgenerator.com/markdown_tables) to load, modify and format the table\n\n<img width=\"371\" alt=\"截圖 2023-06-05 上午10 22 08\" src=\"https://github.com/warren30815/system-design-interview-book-club/assets/36834814/c634e1e9-f1e3-46af-95b6-1ae14bc3887a\" />\n"},{"fields":{"slug":"/content/domain-driven-design/domain-modeling-made-functional/chapter-1/chpater_1/","title":"Domain Driven Design Made Functional"},"frontmatter":{"draft":false},"rawBody":"\n# Domain Driven Design Made Functional\n\n## Chapter 1 Introducing Domain-Driven Design\n\n> 斜體標註部分為重要概念或之後章節會重複提到的詞彙與概念。\n\n### The Importance of a Shared Model\n\n- Functional 主張以 pipeline 的方式組建起整個服務，而為了避免 garbage in garbage out, 第一步最重要的就是釐清需求。\n- 傳統瀑布式開發中，需求從 *Domain Experts* 傳遞到 Architect, 再到 Development team, 最後交付。訊息傳遞可能在其中扭曲或喪失。\n- Agile 講求快速迭代，小量開發成果交付給使用者後得到回饋並改進，但這依然仰賴開發者來轉譯 domain experts 的想法而成為開發成果。\n- 比較好的作法則是，不論是 domain experts, development team, 或是其他 stakeholders, 大家都有一個共通的語言，在這本書中稱為 *Shared Model*.\n- DDD 最重要的幾個流程：\n  - 專注在 *Business Events* 而不是資料結構。\n  - 把一個問題 *Domain* 拆解成更多小的 *Subdomains*.\n  - 替每一個 subdomain 創造一個 *Model*.\n  - 打造一個不論是開發者或非技術人員都能了解的 common language, 或者被稱為 *Ubiquitous Language*.\n\n### Understanding the Domain Through Business Events\n\n- 為什麼要關注事件？企業通常是由一系列 *流程* 組成。所謂的企業流程通常就是將紙本資料做一系列的轉換 (*transformation*)。而每個轉換通常是由某個事件所觸發。這些事件就被稱為 *Domain Events*.\n- *Event Storming*: 召集開發者，領域專家，跟其他關係人，一起做 business event 的 brainstorming.\n- 本書從頭到尾都以一個 *Order-Taking System* 舉例，來說明如何具體了解一個領域。作者虛擬一個叫 Widgets Inc 的工具製造商，並且他的定位如下：\n  - 我們是一個替其他公司生產零件的小公司，生產的東西包含 widgets, gizmos (譯：都是小工具的代稱，不指稱具體事物)。原本都是紙本作業流程，但公司成長的很快，現在想要電子化作業流程。希望有一個網站系統可以讓客人自己下單、確認訂單狀態等。\n- 本書舉例，在 event storming 的過程中，以下是跟一個 Widgets 部門員工的對話：\n  - Ollie：我在訂單處理部門 (order-taking)。主要處理訂單 (orders) 跟詢價單 (quotes)。\n  - 你：什麼事件會觸發你的工作？\n  - Ollie：客人透過 email 寄表單給我們的時候。\n  - 你：所以這個事件應該是 「收到訂單表單」(Order form received) 對嗎？\n  - Ollie：是的。\n  - Sam：我是出貨部門 (shipping department)。我們在訂單被核准後安排訂單出貨。\n  - 你：那你什麼時候開始做這件事？\n  - Sam：當我們從訂單部門接收到一個訂單表單時。\n  - 你：你會怎麼稱呼這個事件？\n  - Sam：「有待處理訂單」(Order available) 如何？\n  - Olie：當有一個訂單已經準備好出貨時，我們會叫他「已下訂訂單」(Placed order)。\n  - Sam: 所以事件名稱應該叫 「訂單已下訂」(*Order placed*) 對吧？\n- 透過以上對話，你得到以下事件\n  - *Order form received*\n  - *Order placed*\n  - *Order shipped*\n  - Order change requested\n  - Order cancellation requested\n  - Return requested\n  - Quote form received\n  - Quote provided\n  - New customer request received\n  - New customer registered\n- 在做 event storming 時有幾個重點：\n  - 一個企業所有人都懂的共同認知模型 (A shared model of the business)：著重在溝通以及了解不同部門的需求，去了解自己不熟悉的地方，釐清自己的錯誤認知。\n  - 讓團隊互相了解 (Awareness of all the teams)：了解其他團隊可能使用到以及如何使用你的部門的產出。舉例，出納部門 (billing department) 也會需要知道 order placed 事件，才能通知客人付款。\n  - 尋找需求之間的代溝 (Finding gaps in the requirements)：當需求都被貼在牆上，很容易找出是否有其他缺漏的事件。\n    - Max：Ollie, 當你準備完一個訂單後，你需要通知客人嗎？我沒看到牆上有這個。\n    - Ollie：噢對，我們會寄信通知客人。應該要有一個事件叫「訂單接收通知已寄出」(*Order acknowledgement sent to customer*)。\n  - 連接各個部門：當事件被放在時間線上，很容易看出部門之間作業的相依性。舉例來說，訂單處理部門 (order taking department ) 處理完訂單後，他們需要告知其他部門，於是 *Order placed* 事件就成了出貨部門 (shipping department) 跟出納部門 (billing department) 的輸入 (input)。\n  - 察覺報表相關的需求：管理階層需要知道企業的營運狀況。\n  - 往兩側延伸可能的事件：從事件的左側與右側繼續問，往往能發現其他事件\n    - 你：Ollie, 什麼會觸發「訂單表單已接收」(Order form received) 事件？\n    - Ollie：我們每天早上查看信箱，另外客人會寄紙本表單給我們，我們打開後歸類為訂單 (orders) 或詢價單 (quotes)。\n    - 你：所以看起來我們還會有個「已收信」(Mail received) 的事件？\n    - ---\n    - 你：Sam, 在你出貨之後，還有什麼事件嗎？\n    - Sam：噢，如果訂單的狀態是「訂單已簽收」(Singed for delivery)，我們會從貨運公司收到通知。讓我增加一個「客人已收貨」(Shipment received by customer) 事件。\n  - 紀錄指令 (*Commands*)：\n    - 是什麼驅使 Domain Events 發生？可能是客人做了什麼，或者老闆叫你做了什麼。在 DDD 中我們稱這些為「指令」(Commands)。\n    - 指令成功的話通常就會啟動一個 *流程* (*Workflow*)。\n    - 有一些命名規則：\n      - *Command: Make X Happen -> Event: X happened*\n      - Command: Send an order form to Widgets Inc -> Event: Order form sent\n      - *Command: Place an order -> Event: Order placed*\n      - Command: Send a shipment to customer ABC -> Event: Shipment sent\n      - 通常是*事件觸發指令，指令觸發企業流程*\n\n### Partitioning the Domain into Subdomains\n\n- 有了 Business Events 後，下一步就是照 Domain 切分他們。\n- 部門 (departments) 通常就是切分 domain 的一個天然依據。\n- 領域 domain 很難有明確的定義。一個有用的方式是，一個領域就是某個領域專家擅長的事情。很繞口嗎？他是ＸＤ但如果你問一個出納部門的人他平常做的事情是什麼，那些事情大概就可以歸賴在「出納」這個領域。\n\n### Creating a Solution Using Bounded Contexts\n\n- 限界上下文 (*Bounded Context*) 的意思就是，把一個 domain 成若干較小且互相不重疊的區塊。\n- 這個名字讓我們把焦點放在，如何劃定他們之間的界線。\n- 每一個限界上下文在實作上會成為一個獨立的元件，有可能有各自的 DLL，一個獨立的服務，或者單純是一個命名空間 (namespace)。\n- 如何把 context 切分乾淨是一門藝術，但可以遵循以下幾個大原則：\n  - 傾聽領域專家：如果一群人用著同樣的詞彙指稱幾件事，並且關注同樣的議題，那他們大概同屬於一個 boudned context.\n  - 觀察既有的團隊與部門界線：這通常就是一個企業如何區分領域的線索。\n  - 注意上下文是「有界的」：小心不要產生範疇潛變 (scope creeping)。需求可能變動，但要踩死界線的劃分。\n  - 為「自主權」而設計：兩個領域或部門結合太死會很難做事，讓每個領域有自主權，能夠有充分資訊並獨立運作，不需要仰賴其他領域，減少相互依賴。\n  - 為企業的無縫運作而設計：假設一個企業流程常常受到其他領域阻擋，考慮將他們合併在一起。即使這樣會讓設計醜一些，但是追求企業價值應該高於追求一個乾淨的設計。\n- 設計上下文對應 (*Context Maps*)：用一個圖表示事件與領域之間的關係，以及他們的上下游關係。\n  - 舉例來說，出貨領域 (shipping context) 是訂單處理領域 (order-taking context) 的下游。\n- 專注在最重要的界限上下文：把重點放在帶來最多企業價值或優勢的領域。\n\n### Creating a Ubiquitous Language\n\n- 讓實作中的命名盡量貼近領域專家的理解。\n- 例如，當領域專家用「訂單」指涉他們平常作業的物件，在你的實作中就應該用 Order 來命名，不要自創一些領域專家看不懂的東西，例如 OrderFactory, OrderManager, OrderHelper 之類的。領域專家看不懂這些東西。至少不要讓他們成為公開 API 或當你需要與其他人溝通時的設計詞彙。\n- 通用語言 (*Ubiquitous Language*)，也稱為「無所不在的語言」，指的是一系列的概念與詞彙，被團隊的所有成員所理解與共用。不只在設計中，也應該在你的實作與 codebase 中。\n- 注意每個領域對同一個詞彙的理解跟用途可能不同。在我們的例子中，order 這個詞在不同的部門中都會用到，但其實出貨部門的「訂單」跟出納部門的「訂單」其實意義不太一樣。所以命名時也會需要用一些前綴或後綴來區分上下文。\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/chapter-1/chapter_1/","title":"第一章：使用者人數 -- 從零到百萬規模"},"frontmatter":{"draft":false},"rawBody":"# 第一章：使用者人數 -- 從零到百萬規模\n\n此篇主要在講最簡單的單台主機設置，到百萬規模的系統，中間如何逐步加入各個元件，以及每個元件如何擴展。\n經過第一章的介紹，便可以對一個可規模化 (scalable) 的系統有相對完整與綜觀的認識。\n\n## 單台主機\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. DNS server\n3. Web server\n\n主要流程：\n\n1. 客戶端發起請求\n2. DNS 伺服器解析出網站伺服器 IP\n3. 網站伺服器處理流量\n\n## 資料庫\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. DNS server\n3. Web server\n4. Database\n\n主要流程：\n\n1. 客戶端發起請求\n2. DNS 伺服器解析出網站伺服器 IP\n3. 網站伺服器處理流量\n4. 網站伺服器向資料庫請求資料，或送出資料修改請求\n\n資料庫型態：\n\n1. 關聯式資料庫 (RDBMS)\n2. 非關聯式資料庫 (NoSQL)\n   1. CouchDB\n   2. Cassandra\n   3. Hbase\n   4. AWS DynamoDB\n\n## 擴展\n\n1. 垂直擴展：加大機器的 CPU, memory, disk 等硬體處理能力。但存在以下問題：\n   1. 一台機器的運算與儲存擴展有硬體上的極限\n   2. 會造成單點故障 (single point of failure), 即系統的單一節點故障便導致整個系統變得不可用\n2. 水平擴展：增加更多台機器。能夠解決以上問題，也是在討論擴展時的主要對策。\n\n## 負載平衡 (Load Balancer)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. DNS server\n3. *Load Balancer*\n4. Web server\n5. Database\n\n主要流程：\n\n1. 客戶端發起請求\n2. DNS 伺服器解析出網站伺服器 IP\n3. *負載平衡接收流量後往後面多台機器分配請求*\n4. 多台網站伺服器處理流量\n5. 網站伺服器向資料庫請求資料，或送出資料修改請求\n\n解決的問題\n\n1. 可透過增加網頁伺服器數量來處理更多的請求，解決了擴展性的問題 (scalability)\n2. 當有一台機器故障時，負載平衡器可以將請求發送至其他運作中的機器，增加了可用性 (availability)\n\n注意事項：\n\n1. 由於資安因素，通常網頁伺服器會透過內網通訊，只有負載平衡器連接外網\n2. 負載平衡器可能變成系統中單點故障所在，但可使用 DNS server 的循環解析 (Round-robin DNS resolution) 或其他方式來解決單點故障問題\n\n## 資料庫複製 (Database Replication)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. DNS server\n3. Load Balancer\n4. Web server\n5. *Database with multiple replica*\n\n主要流程：\n\n1. 客戶端發起請求\n2. DNS 伺服器解析出網站伺服器 IP\n3. 負載平衡接收流量後往後面多台機器分配請求\n4. 多台網站伺服器處理流量\n5. 網站伺服器向資料庫請求資料，或送出資料修改請求\n6. *資料庫主節點(master)負責處理寫入與讀取，從節點(slave)負責處理讀取請求*\n\n解決的問題\n\n1. 當讀取資料的請求很多時，從節點可分攤讀取請求，並且可透過增加從節點來達成擴展\n2. 資料備份：即使有節點損毀，依然能保證可以從其他節點獲得完整的數據\n\n## 快取 (Cache)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. DNS server\n3. Load Balancer\n4. Web server\n5. *Cache*\n6. Database with multiple replica\n\n主要流程：\n\n1. 客戶端發起請求\n2. DNS 伺服器解析出網站伺服器 IP\n3. 負載平衡接收流量後往後面多台機器分配請求\n4. 多台網站伺服器處理流量\n5. 網站伺服器向*快取*請求資料，或送出資料修改請求\n6. *快取負責暫時性儲存資料，回應伺服器需求*\n7. 資料庫主節點(master)負責處理寫入與讀取，從節點(slave)負責處理讀取請求\n\n注意事項\n\n1. 使用快取最需要關注的問題是決定何時資料是失效的，可能的方法有\n   1. 快取壽命 (Time to live, TTL)：快取資料經過特定時間長度後即視為無效\n   2. Read-through：快取接收到請求時判別有沒有資料，有就回傳，沒有的話從資料庫拿取，回應請求，並貯存在快取中\n   3. Write-through：服務接收到寫入請求時，同時往快取與資料庫寫入資料，以保證資料都是最新的。缺點是兩邊都要寫入可能導致回應時間變長\n2. 快取滿了的時候的處理方式\n   1. LRU (Least-recently-used)：上次被使用時間距今最久的先清掉\n   2. LFU (Least-frequently-used)：最不常使用到的先清掉\n   3. FIFO (First-in-first-out)：先進來的先清掉\n\n## 內容傳遞網路 (Content Delivery Network, CDN)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. *CDN*\n3. DNS server\n4. Load Balancer\n5. Web server\n6. Cache\n7. Database with multiple replica\n\n主要流程：\n\n1. 客戶端發起請求\n2. *對於靜態資料如圖片或指令碼，CDN 能夠直接回應請求，減少系統負擔*\n3. DNS 伺服器解析出網站伺服器 IP\n4. 負載平衡接收流量後往後面多台機器分配請求\n5. 多台網站伺服器處理流量\n6. 網站伺服器向快取請求資料，或送出資料修改請求\n7. 快取負責暫時性儲存資料，回應伺服器需求\n8. 資料庫主節點(master)負責處理寫入與讀取，從節點(slave)負責處理讀取請求\n\n注意事項：\n\n1. CDN 通常在全球分佈，接收並處理地理距離上較近的請求，以減少回應時間\n2. CDN 也要注意如何使資料無效 (invalidation)，常見的方法有\n   1. TTL：經過一定時間後資料無效\n   2. 版本：在 URL 攜帶版本號，因此當客戶端請求不同版本時，CDN 便會向伺服器詢問最新版的資料\n\n## 伺服器狀態 (Stateful vs Stateless)\n\n### Stateful\n\n伺服器會將使用者資料貯存在同個伺服器上，例如將會話 (session) 存在機器上\n\n問題：當水平擴展時，如果使用者的請求被負載平衡器分配到不同的機器上，則該機器沒有使用者的會話資料，將導致系統出現預期外的行為\n\n### Stateless\n\n伺服器將所有的資料貯存在第三方元件或系統中，而非自身的貯存空間\n\n伺服器在處理請求時，可以把每個請求看成獨立的流程來處理，不需要考慮當下請求跟之前的請求有沒有關聯，也不需要考慮該請求所需要的資訊是否存在自己的貯存空間中\n\n可用的會話資料處存方案：\n1. Memcached\n2. Redis\n3. NoSQL\n\n備注：\n1. 在討論水平擴展時，通常假設伺服器是無狀態的，這樣在部署時就不需要考慮負載平衡器該如何解決前後請求之間的關係\n2. 即使如此，一些負載平衡器還是可以提供所謂\"親和性\"的機制 (affinity)，例如將來自同一個 IP 的請求都分配到同一台機器上\n\n## 資料中心 (Data Centers)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. CDN\n3. DNS server\n4. Load Balancer\n5. *Web server in multiple data centers*\n6. Cache\n7. Database with multiple replica\n\n主要流程：\n\n1. 客戶端發起請求\n2. 對於靜態資料如圖片或指令碼，CDN 能夠直接回應請求，減少系統負擔\n3. DNS 伺服器解析出網站伺服器 IP\n4. 負載平衡接收流量後往後面多台機器分配請求\n5. *多台網站伺服器分布在不同的資料中心中處理流量*\n6. 網站伺服器向快取請求資料，或送出資料修改請求\n7. 快取負責暫時性儲存資料，回應伺服器需求\n8. 資料庫主節點(master)負責處理寫入與讀取，從節點(slave)負責處理讀取請求\n\n注意事項：\n\n1. DNS 通常會根據使用者的地理位置來解析請求，回應請求一個距離使用者較近的資料中心\n2. 這裡雖然用的名稱是 Data Center, 但我認為用 AWS 的 Availability Zone 來說明會更好解釋。即不同的資料中心是在地理距離上分佈相距較遠的，如此一來可以在某區域發生災害時依舊保證有其他地理區域的資料中心依舊可用。例如當 ap-northeast-1 (東京) 的資料中心所在區域發生地震時而導致資料中心不可用時，us-east-2 依舊可用，不會因為地理位置相近而導致所有資料中心同時損毀。\n\n## 訊息隊列 (Message Queue)\n\n關鍵元件：\n\n1. Client (web, mobile)\n2. CDN\n3. DNS server\n4. Load Balancer\n5. Web server in multiple data centers\n6. *Message Queue*\n7. *Workers*\n8. Cache\n9. Database with multiple replica\n\n主要流程：\n\n1. 客戶端發起請求\n2. 對於靜態資料如圖片或指令碼，CDN 能夠直接回應請求，減少系統負擔\n3. DNS 伺服器解析出網站伺服器 IP\n4. 負載平衡接收流量後往後面多台機器分配請求\n5. 多台網站伺服器分布在不同的資料中心中處理流量\n6. 網站伺服器向快取請求資料，或送出資料修改請求。*長時間操作則將資訊送往訊息隊列*\n7. *Worker 接受隊列內的消息並逐一處理*\n8. 快取負責暫時性儲存資料，回應伺服器需求\n9. 資料庫主節點(master)負責處理寫入與讀取，從節點(slave)負責處理讀取請求\n\n注意事項\n\n1. Queue 只是這邊提到的一種方式，其他的訊息溝通系統還包含生產-訂閱 (Pub/Sub) 等機制。\n2. 費時較長且不需要使用者立即得知結果的操作，設計上通常不會由網站伺服器處理，這時就可以讓網站伺服器把這類工作打包成訊息，丟到隊列中，並且由特定的工作伺服器 (worker) 去消化隊列訊息，並異步處理。\n3. 常見的應用情境包含：寄信、影像處理、資料分析。\n4. Queue 的作用還包含服務之間的*去耦合*，即讓接收訊息與處理訊息者不需要了解彼此的部署與實作，並且兩者可以實現不同的擴展策略。\n\n## 日誌、指標、自動化 (Logging, Metrics, Automation)\n\n- 日誌：對於了解服務哪裡出錯以及獲取除錯所需的資訊來說至關重要\n- 指標：了解服務的關鍵資訊，例如回應時間、系統負載、使用者數量、關鍵業務請求數量等\n- 自動化：使用 CI/CD 等手段確保即使系統成長的更加複雜，大量事務能夠被自動化處理，服務能持續運行\n\n## 資料庫水平擴展\n\n擴展方法：\n\n1. 垂直擴展：加大機器處理與貯存的運算能力\n2. 水平擴展：分片 (Sharding)\n\n注意事項\n\n1. 分片需注意使用什麼欄位作為 Sharding key，要避免資料集中在一個分片上\n2. 若要重新分片資料時會是個複雜的挑戰\n3. 名人問題：大量讀取可能都是針對少部分資料，導致特定分片承受大量流量，而其他分片則閒置\n4. 分片會使得要做 join 等聚合操作時變得困難，這些邏輯可能需要在應用層完成\n5. 資料庫擴展方法有很多，這裡提到的主從式架構 Master-slave 只是其中一種，其他還有包含\n   1. Multi-master\n   2. Consistent Hashing\n   3. Partitioning\n   4. Distributed Transaction\n   5. Command Query Responsibility Segregation\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/chapter-10/chapter_10/","title":"design pattern (notification)"},"frontmatter":{"draft":false},"rawBody":"# design pattern (notification)\n\n## notification 種類\n通知向用戶發出重要訊息提醒，例如新聞、產品更新、活動等等。引經在日常生活中是不可或缺的一部分，通知系統並不只有 mobile 的通知提醒而已，而是有三種格式。\n* push notification\n* SMS\n* Email\n\n![](https://hackmd.io/_uploads/Hyek7XC6h.png)\n\n## notification design pattern 問題定義\n\n構建一個每天發送數百萬條通知的可擴展系統並不是一件容易的事。它需要對通知生態系統有深入的了解。這邊簡單給大家看一下面試過程。\n\n`主考官：`系統支持哪些類型的通知？\n`面試者：`推送通知、短信、電子郵件。\n\n`主考官：`是實時系統嗎？\n`面試者：`就說它是一個軟實時系統吧。我們希望用戶盡快收到通知。但是，如果系統工作負載較高，輕微的延遲是可以接受的。\n\n`主考官：`支持哪些設備？\n`面試者：`iOS 設備、Android 設備、PC/mobile。\n\n`主考官：`什麼會觸發通知？\n`面試者：`通知可以由客戶端應用程序觸發。它們也可以在服務器端進行安排。\n\n`主考官：`用戶可以選擇退出嗎？\n`面試者：`是的，選擇退出的用戶將不再收到通知。\n\n`主考官：`每天發出多少條通知？\n`面試者：`1000萬條移動推送通知、100萬條短信、500萬封電子郵件。\n\n`補充一下` : 這邊指的退出是可以是關閉通知，或是取消訂閱某一個頻道跟 email\n\n## muti notifaction design pattern\n這邊主要介紹，iOS 推送通知、Android 推送通知、短信和電子郵件。它的內容如下：\n\n• 不同類型的通知\n• 聯繫信息收集流程\n• 通知發送/接收流程\n\n### iOS push notification\n![](https://hackmd.io/_uploads/SkF1c7CT3.png)\n主要有三個部分完成 iOS push notification\n\n* Provider ： 用來發送 push noticiaction request 到 APNS，可以是你的本地終端機，或是其他 microservices 服務，其中 request 包含。\n\n  **Device token** : 每個 user 的裝置 id。\n  **Payload** ： notification 的 Payload\n  ![](https://hackmd.io/_uploads/HJjvsmCa3.png)\n\n* APNS (Apple Push Notification Service) : 這是 APPLE 用來處理 propagate 的 remote service ，用來 push notification 到 IOS decives。\n* iOS Device: client device 用來獲取 push noticiaction\n\n### android push notification\n\n在 android 上主要是透過 FCM 去完成這件事 ( firebase cloud message)，而這邊可以搭配的 provider 目前筆者習慣是透過 `cloud functions` 搭配 `fire store`去做 `realtime database` 去觸發 `cloud message` 。\n\n這邊補充下狐狸提問的可不可以用 `cloud run` 去執行這件事，本人覺得 `cloud run` 本身的定位不太適合放在這邊，雖然 `cloud run` 跟`cloud functions` 都是 Serverless，但 `cloud run` 主要是為了更好搭配 `GCP` 上面的服務例如 `Cloud Monitoring`、`Cloud Logging、Cloud Trace `和 `Error Reporting`等等同時 `cloud run` 是屬於 `container base` 應用，所以在 `cloud run` 會用到的環境都需要透過 `image`  去打包，但其實我們只是需要簡簡單單的 `serverless function`，用 `cloud run` 來做 web api 過程相對比較複查，同時延遲性或是穩定不一定有保證，有點大材小用，而且也不好搭配 firebase 做 real time database。\n\n\n對於快速建置小批量的工作流程或單一 Function-based 的服務，這邊比較推薦用 `cloud functions`\n\n![](https://hackmd.io/_uploads/r1s3fZkR3.png)\n\n![](https://hackmd.io/_uploads/SyXL6e102.png)\n\n### SMS\n常見的 server 例如 ： Twilio 、Nexmo\n\n\n![](https://hackmd.io/_uploads/SyqQbZyC3.png)\n### email\n通常會搭配第三方工具例如 ： `nodemailer`\n\n但本人目前適用 `nextjs` 推薦的 \nsender server (Resend) : https://resend.com/docs/send-with-nodejs\ntemplate (react email): https://react.email/docs/introduction\n\n![](https://hackmd.io/_uploads/ry3GbW10h.png)\n\n整體架構如下\n![](https://hackmd.io/_uploads/SJPM4-JRh.png)\n\n## store user token\n要發送通知，我們需要收集 decive token、電話號碼或電子郵件地址。當用戶安裝我們的應用程序或第一次註冊時，API服務器會收集用戶聯繫信息並將其存儲在數據庫中。\n![](https://hackmd.io/_uploads/S10qNZkRn.png)\n![](https://hackmd.io/_uploads/ryMh4-kAh.png)\n\n\n## 通知發送/接收流程\n\n### High-level design\n\n![](https://hackmd.io/_uploads/SkOAH-k03.png)\n\n\n* Service 1 to N: 服務可以是微服務、cron 作業或觸發通知發送事件的分佈式系統。例如，計費服務會發送電子郵件提醒客戶到期付款，或者購物網站會通過短信告訴客戶他們的包裹將於明天送達。\n* Notification system: 通知系統是發送/接收通知的核心。從簡單的事情開始，只使用一個通知服務器。它為服務 1 到 N 提供 API，並為第三方服務構建通知負載。\n* Third-party services: 如上一節介紹的 notification services ，這邊要注意的是對於新市場或未來不可用，例如 fmc 不能在中國使用，所以改成 Jpush、PushY 等等。\n* iOS, Android, SMS, Email: User 獲取裝置的地方.\n\n這樣的設計模式就衍生出以下問題：\n*  Single point of failure (SPOF) ： 只要是單體是架構就會出現的問題。\n*  Hard to scale ： notification systems 只在一台 services 中負責所有通知的訊息，對於要獨立 database 的擴展或是 cache 都是不太容易做到。\n*  Performance bottleneck ：處理和發送通知會非常佔用系統資源，例如 email 一邊要處理 html 內容，還要等第三方服務 api 結果，在一個系統處理所有事情會造成系統過載狀況，尤其實在高峰時段，而衍生 SPOF 等問題。\n\n## improved\n• 將 database 和 cache 移出 notification services。\n• 添加更多 notification servers  並設置自動水平縮放。\n• 添加 message queue 並設置自動水平縮放，透過 retry error 減少 api 來回，同時解耦系統組件。\n![](https://hackmd.io/_uploads/Hy1moW1R3.png)\n\n**Service 1 to N:** 它們代表通過通知服務器提供的API發送通知的不同服務。\n\n**Notification servers:**\n*  為服務提供API 以發送通知。這些 API 只能在內部訪問 或由經過驗證的客戶來防止垃圾郵件。\n*  執行基本驗證以驗證電子郵件、電話號碼等。\n*  查詢數據庫或緩存以獲取呈現通知所需的數據。  將通知數據放入消息隊列以進行並行處理。\n\n例如：\nPOST https://api.example.com/v/sms/send\nRequest body\n\n![](https://hackmd.io/_uploads/B1mqJfk0h.png)\n\n**消息對列** ：他們刪除組件之間的依賴關係。當要發送大量通知時，消息隊列充當緩衝區。每種通知類型都分配有不同的消息隊列，因此第三方服務的中斷不會影響其他通知類型。\n\n**Workers**：用於監聽 handle notification service event。\n\n\n小結：\n1. 服務調用通知服務器提供的 API 來發送通知。\n2. 通知服務器從緩存或數據庫中獲取元數據，例如用戶信息、設備令牌和通知設置。\n3. 將通知事件發送到相應的隊列進行處理。例如，iOS 推送通知事件被發送到 iOS PN 隊列。\n4. Workers 從消息隊列中拉取通知事件。\n5. 第三方服務向用戶設備發送通知。\n\n## Design deep dive\n\n*  可靠性。\n*  其他組件和注意事項：通知模板、通知設置、速率限制、重試機制、推送通知的安全性、監控排隊通知和事件跟踪。\n*  更新設計。\n\n### Reliability 可靠性\n\n在分布式系統設計中一定會考量的問題點。\n\n#### 我們要怎麼防止資料遺失？\n我們可以透過 workders 中觸發 notification log 去記錄每次推波的時間點與使用者相關數據，此用意可以來對照持久話 db 中的資料是否有匹配。\n![](https://hackmd.io/_uploads/SyDE8GkC2.png)\n\n#### 收件人只會收到一次通知嗎？\n\n理想情況是不會，但分布式特性可能會導致重複通知，也許是延遲或是資料不齊全的情形，為了繳少重複狀況發生，需要新增預防重複新增數據的機制，例如當第一次事件發送時隨機生成指定 event_id，當下次要再重新發送推波時會去比對 db 中是否已經存在的 event_id，以此來避免推波多次狀況。\n\n### Additional components and considerations\n通知還有其他考量的點例如：\n\n* 模板重用\n* 通知設置\n* 事件跟踪\n* 系統監控\n* 速率限制\n\n#### 模板重用 ( Notification template )\n通知系統每天都會發出數百條的通知內容，總不可能每次都重新生成模板，這時你可以考慮先 prebuild 格式化模板的通知，之後只需要自定義參數或是相關 link 內容就好，減少模板建制時間。\n\n例如你可以寫一個 `serverless function` 去 build email template。\n```typescript\nimport type { NextApiRequest, NextApiResponse } from 'next';\nimport { EmailTemplate } from '../../components/EmailTemplate';\nimport { Resend } from 'resend';\n\nconst resend = new Resend(process.env.RESEND_API_KEY);\n\nexport default async (req: NextApiRequest, res: NextApiResponse) => {\n  try {\n    const data = await resend.emails.send({\n      from: 'Acme <onboarding@resend.dev>',\n      to: ['delivered@resend.dev'],\n      subject: 'Hello world',\n      react: EmailTemplate({ firstName: 'John' }),\n    });\n\n    res.status(200).json(data);\n  } catch (error) {\n    res.status(400).json(error);\n  }\n};\n```\n\n#### 通知設置 ( Notification setting )\n堆用戶來說每天都要接受非常多的通知內容，所以勢必需要針對推波進行分類，實際情況中我們在推波信息的前置作業是，需要先判斷用戶是否有訂閱某一個 channel 或是用戶是否取消訂閱，這些都是需要考慮的因素，如果 user 要訂閱每一個 channel (topic) 的話會去綁定 devicedtoken ，也就是下方的 \n`YOUR_REGISTRATION_TOKEN` 內容。\n\n```typescript\n// These registration tokens come from the client FCM SDKs.\nconst registrationTokens = [\n  'YOUR_REGISTRATION_TOKEN_1',\n  // ...\n  'YOUR_REGISTRATION_TOKEN_n'\n];\n\n// Subscribe the devices corresponding to the registration tokens to the\n// topic.\ngetMessaging().subscribeToTopic(registrationTokens, topic)\n  .then((response) => {\n    console.log('Successfully subscribed to topic:', response);\n  })\n  .catch((error) => {\n    console.log('Error subscribing to topic:', error);\n  });\n  \n\ngetMessaging().unsubscribeFromTopic(registrationTokens, topic)\n  .then((response) => {\n    console.log('Successfully unsubscribed from topic:', response);\n  })\n  .catch((error) => {\n    console.log('Error unsubscribing from topic:', error);\n  });\n```\n\n####  Rate limiting\n之前讀書會有提到。\n\n#### Retry mechanism\n當地三中服務發送通知失敗，會將該通知重新放到訊息隊列中，也就是上面的 retry ，如果超過 retry 次數時就通知開發人員並發送警報。\n\n#### Security in push notifications\n對於 IOS 或是 android 用戶有提供 appKey 跟 appSecret 來保護推波 api 的安全因為會需要身份驗正。\n\n#### Events tracking\n透過 Monitor queued notifications 我們可以分析用戶行為，了解用戶參與度，甚至分析服務實現，與事件追蹤情況例如 `sentry`。\n![](https://hackmd.io/_uploads/SJ_jZX1R3.png)\n![](https://hackmd.io/_uploads/Sy5oZ7kA2.png)\n\n#### finally design\n\n![](https://hackmd.io/_uploads/SyMdMmyC3.png)\n\n#### 最後總結一下優化哪些功能：\n• 通知服務器配備了兩個更關鍵的功能：身份驗證和速率限制。\n• 透過重試機制來處理通知失敗。如果系統無法發送通知，它們將被放回消息隊列中，開發者定義重識次數，都失敗發送警報。\n• 通知模板提供一致且高效的通知創建過程。\n• 添加了監控和跟踪系統，用於系統健康檢查和未來改進。\n\n### demo 時間\n![](https://hackmd.io/_uploads/BkAM-m1Rh.png)\n![](https://hackmd.io/_uploads/rJim-XJCn.png)\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/chapter-4/chapter_4/","title":"第四章：設計網路限速器"},"frontmatter":{"draft":false},"rawBody":"# 第四章：設計網路限速器\n\n## # 主軸\n\n- 主要在 Layer 7: Application layer\n\n- 作用：\n\n  - 防止 DoS: 避免資源餓死 (resouce starvation)\n  - 節省流量成本: 流程內可能會調用到第三方服務 (依次計費), 或者 LB 依請求次數計費, 如果能在避免資源餓死的前提下作考量時, 那麼大部分的請求被拒絕時, 自然而然以上的成本會下降\n  - 防止超載: 會打請求的未必只是人還有Bot, 為了避免大家把有限資源的服務器打暴為前提做設計 (更多能參考SLA)\n\n- 目標：\n\n  - server-side API rate limiter\n\n    - REF: client: axios-rate-limit: other will be delayed automatically.\n\n  - a large number of requests --> Low latency & little memory？\n \n  - 聚合用的欄位, 希望足夠彈性\n\n  - exception handling, inform users\n\n  - service (API Gateway) vs server-side code\n\n  - work in distributed environment, 在這裡指的是 Rate limiter 本身可能不只是 cluster, 甚至跨 VPC, 跨 AZ 的環境\n\n  - high fault tolerance: Rate limiter 本身非業務流程上的必要功能, 它本身的好壞不該影響到整個系統, 因此考量時, 該怎設計隔離 rate limte service 某個節點異常的部份\n \n  - low latency: rate limit本身非業務所需功能, 不應該在latency上佔比過高\n\n  - technology stack\n\n  - algorithm 可選性\n\n  - 時間成本\n\n## # Algorithm\n\n- 演算法介紹\n\n  - Token bucket\n\n  - Leaking bucket\n\n  - Fixed window counter\n\n  - Sliding window log\n\n    - 可在每次收到請求時，才清除舊資料。安排固定時間或長度清除\n    \n    Q: 為什麼連被拒絕的請求也要加入 log 做計數？\n    \n    A: 這個的設計其實不是為了直接給 rate limiter 來計算用的，而是其他需求，畢竟叫做 log，像 nginx access log 一樣，有請求來的本來就都會被紀錄，有以下四個常見需求：\n    \n       1. 故障排查用: 被拒絕的請求可能表示系統中存在問題。例如，如果出現許多請求被拒絕，可能意味著系統超負荷、有 bug、或者資源分配不足。透過記錄被拒絕的請求，工程師能夠回溯問題並進行修復。\n       2. 監控系統負載: 大量的被拒絕的請求可能表示系統負載過高或者資源短缺。這些日誌可以作為我們監控系統狀態和評估資源需求的依據。\n       3. 離線用戶行為分析: 對於被拒絕的請求進行記錄和分析，可以幫助我們更好地了解用戶的行為模式，以及那些功能或服務可能存在問題。然後我們就可以對這些問題進行調整和優化。\n       4. 法規和合規需求: 在某些情況下，法規可能要求我們記錄所有的請求，包括被拒絕的請求。\n    \n    ref: [Rate limiting - why log rejected requests' timestamps in Sliding window log algorithm?](https://www.reddit.com/r/AskComputerScience/comments/xktn2j/rate_limiting_why_log_rejected_requests/)\n\n  - Sliding window counter\n\n- 演算法比較\n\n  - Bucket vs Window\n\n    - 可看作 Bucket 可以把可接受的峰值跟均速分開設定，Window 把峰值跟均速綁在一起\n    - 因此 Bucket 需要調整兩個參數達到平衡，也相對較困難\n\n  - Bucket\n\n    - A. Token bucket\n\n      - 適合處理瞬間流量，如搶購\n      - 比 B 更有效的利用資源\n\n    - B. Leaking bucket\n\n      - 穩定輸出模型\n      - 不適合瞬間流量，如搶購。因為即使流量在可接受範圍，依然會按照一個速率進行\n\n  - Window\n\n    - C. Fixed window counter\n\n      - 可能會有時間差聚集現象，實質上超過流量\n\n    - D. Sliding window log\n\n      - 解決 C 的問題，一定不會超過流量限制\n      - 大量耗費記憶體，因為須記錄所有 timestamp\n      - 清除舊資料很耗時\n\n    - E. Sliding window counter\n\n      - 解決 D 的記憶體使用問題，但保有大概率解決 C 的問題，不會超過流量\n      - 實驗統計只有 0.003% 出錯\n\n## # High-level architecture\n\n## # Design deep dive\n\n- Rate limiting rules 怎被建立、儲存、存取和更新: 依照結構化格式(YAML, JSON, XML...)，將規則的欄位給格式化\n\n- Exceeding the rate limit\n\n  - HTTP 429 (Too many requests)\n\n    - 放到待處理\n    - 直接捨棄\n\n  - Rate limiter headers\n\n    - 沒超過限制\n\n      - X-Ratelimit-Remaining: 在時間區間內還剩下多少配額\n      - X-Ratelimit-Limit: 在時間區間內，客戶端請求的限額\n      - X-Rate-Limit-Reset: 一個代表時間的數值，時間到將重設配額\n\n    - 超過限制回傳 429\n\n      - X-Ratelimit-Retry-After: 指定客戶端在傳送下一個要求之前所應等待 (或睡眠) 的秒數。如果重試值沒過就傳送要求，則不會處理要求，並且會回傳新的重試值。\n     \n      **Client需要知道這些資訊，才好控制下一次發出請求 (甚至也能說是一種Retry policy的控制)**\n\n- Detailed design\n\n  Q: 這些資訊適合存放在哪？\n  \n  A: RDBMS太慢且本身的資料結構也不適合存放大量數據，且有熱點存取問題，因此選擇 in memory store 是適合的，夠快且過期的資料通常 in-memory db 有配合的機制能汰除掉，因為我們這裡大部分都只要計次 (sliding window log 例外)，Redis有提供INCR與EXPIRE (甚至TTL機制)，便於使用\n\n- Rate limiter in a distributed environments\n\n  - Race condition (類似超賣問題)\n\n    - Locks\n\n      - 會降低效能，吞吐量會受影響\n\n    - Lua script\n\n      - 因為是「原子性的」\n      - 因為 lock 是對資源層級的鎖定，靈活性較低，以原子性的腳本來做，能夠只在需要的步驟上使用\n\n    - sorted sets data structure\n\n      - [Skip List](https://mecha-mind.medium.com/redis-sorted-sets-and-skip-lists-4f849d188a33)\n\n  - Synchronization issue\n \n    在跨 VPC / AZ 的情況下，很可能 rate limiter 內的資訊與狀態不一致，對同一個user，不同請求會隨機跳轉到不同 rate limiter 上被處理，那就等於白搭了，所以在這裡會建議用同一個 redis cluster，以及啟用 sticky session機制，讓同一個 user 的不同請求都能在同一個 rate limiter 上被處理\n\n    - sticky sessions\n\n      - 讓 client 去固定 rate limiter，不彈性不好擴展\n\n    - centralized data stores\n\n      - REF: [A Comprehensive Guide to Distributed Caching](https://blog.devgenius.io/a-comprehensive-guide-to-distributed-caching-827f1fa5a184)\n\n- Performance optimization\n\n  - multi-data center\n  - eventual consistency model\n    - 相較於完全一致性更有效率，但又保有一致性\n    - chaper 6\n\n- Monitoring\n\n  - 需監控以下兩個面向是否能有效地達到目的\n\n    - rate limiting rules\n    - rate limiting algorithm\n      - EX. flash sales --> Token bucket\n\n## # 延伸討論\n\n- 不同 layer 的防範\n\n  - 在 layer 3 進行較快？\n  - 全公司同一個 ip\n  - 沒登入時 (也可在 layer 7 用 session)\n  - 針對不同類型使用者，不同策略\n  - 不同 layer 的防範，不是選擇，而是一起用，各自防不同面向。但用太多會不會影響到單次請求的效能？\n\n- 加強 client，避免問題\n\n  - client cache\n  - 合理的發送請求？\n  - catch exceptions or errors\n  - back off time：可用指數型成長策略\n\n- Hard vs Soft\n\n  - Hard rate limiting\n\n    - 超過限制的請求將被直接拒絕或返回錯誤\n    - 確保系統在特定時間內不會超過預定的請求速率\n    - 可能導致客戶端體驗不佳\n\n  - Soft rate limiting\n\n    - 允許短期內超過限制的請求，但在長期內維持平均速率不超過預定的限制\n    - 通常使用 Bucket 演算法\n\n- 當服務器「總負載」快要超出限額，會怎麼做？\n\n  - 平均調低 rate limit threshold\n  - 把流量留給重要的請求或用戶\n  - 大家都暫停別用\n  - 機器開下去\n  - 其他\n\n- Circuit breaking（熔斷）和 degradation（降級）\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/chapter-7/chapter_7/","title":"第七章：設計可用於分散式系統的唯一 ID 生成器"},"frontmatter":{"draft":false},"rawBody":"# 第七章：設計可用於分散式系統的唯一 ID 生成器\n\n## 前言\n\n唯一 ID 在系統中很重要，在單資料庫伺服器中，可以利用 primary key + _auto_increment_ 屬性來實作唯一 ID，但在分散式系統中，有多資料庫伺服器間的同步問題，本篇會介紹四種方法，以及各自的優缺點及使用時機\n\n## 步驟一：需求範圍確認\n\nQ: 唯一 ID 須具備哪些性質\n\nA: 須為唯一且可依時間先後排序\n\nQ: 新生成的 ID，是否為上一個 ID + 1\n\nA: ID 需隨時間嚴格遞增，但不一定需要絕對差距 1\n\nQ: ID 是否全為數字，還是可以有文字\n\nA: 需全為數字\n\nQ: ID 的長度有限制嗎\n\nA: 需為 64 bits\n\nQ: 系統的規模有多大\n\nA: 每秒需要能產生 10,000 IDs\n\n## 步驟二：high-level 架構\n\n四種分散式系統中唯一 ID 的設計方法：\n\n1. Multi-master replication\n2. Universally unique identifier (UUID)\n3. Ticket server\n4. Twitter snowflake approach\n\n### Multi-master replication\n\n![](assets/multi_master.png)\n\n如圖，還是利用資料庫的 _auto_increment_ 功能，只是不是 + 1，而是比如有 k 個資料庫就 + k，圖中 k = 2\n\n缺點：\n\n1. 多個資料中心下很難擴充\n2. ID 的值不一定隨著時間嚴格遞增，比如有一台產生較多，一台產生較少，那後者產生出的 ID 數值即使生成時間較晚，但 ID 數值仍會小於前者生成較早的 ID\n3. 很難 auto-scale 伺服器\n4. 離線時無法使用\n\n### UUID（Universally Unique Identifier）\n\nUUID 是一個能產生 128 bits ID 的演算法，有著極小的碰撞概率，每秒產生 10 億個 UUID 的情況下持續 100 年，只有 50% 的機率會碰撞\n\n一個 UUID 的範例：_09c93e62-50b4-468d-bf8a-c07e1040bfb2_，32 個 16 進位的字元，所以為 128 bits (32 \\* 4)\n\n因為有著極低的碰撞概率，因此可以每個伺服器都跑自己的 UUID 生成器，如下圖：\n\n![](assets/uuid.png)\n\n註：uuid 演算法\n\n---\n\n分成 v1 ～ v5，根據 uuid.js 統計有 77% 使用者選擇 v4；21% 使用者選擇 v1，有特殊需求才會選 v5 & v3，v2 基本上不採用 ([ref1](https://yuanchieh.page/posts/2020/2020-12-01-uuid-%E5%8E%9F%E7%90%86%E8%88%87%E5%AF%A6%E4%BD%9C%E5%88%86%E6%9E%90-%E8%A9%B2%E5%A6%82%E4%BD%95%E6%8C%91%E9%81%B8%E9%81%A9%E5%90%88%E7%9A%84-uuid-%E7%89%88%E6%9C%AC/))，使用時機可大略分為 ([ref2](https://stackoverflow.com/questions/20342058/which-uuid-version-to-use)、[ref3](https://www.uuidtools.com/uuid-versions-explained))：\n\n_只是單純需要一個隨機不重複的 uuid_：v4，會從超過 5.3 x 10^36 種可能的 uuid 裡面隨機生成出一個，分為兩個變化版，variant-1 為 Minecraft 中使用的演算法；variant-2 即 Microsoft 系統內的 GUID [ref3]\n\n_需要在前者的基礎上知道時間資訊（精度到 100 nanoseconds）和是哪台機器產生的_：v1，格式見下圖，前三組為時間資訊，表示從 1582-10-15 00:00:00 到現在經過了多少個 100 ns ([ref4](https://stackoverflow.com/questions/3795554/extract-the-time-from-a-uuid-v1-in-python))，low time 代表算出的間隔的最後 32 bits；mid time 為中間 16 bits；第三項為版本資訊 + 開頭 16 bits；第四項為 variant 編號 + system clock 值；第五項為網卡的 mac address\n\n![](assets/uuid_v1.png)\n\n要 decode 出時間的話，可參考該 python code ([ref5](https://stackoverflow.com/questions/17571100/how-to-extract-timestamp-from-uuid-v1-timeuuid-using-javascript)):\n\n![](assets/uuid_v1_decode.png)\n\n_需要能根據 namespace + input 產生 reproducible 的 uuid_：用 v3 或 v5，v3 將 input 用 MD5 hash；v5 用 SHA-1 hash，所以 v5 較 v3 安全\n\nnamespace 可以視為你的 key 的概念，範例可見 [ref6](https://stackoverflow.com/questions/10867405/generating-v5-uuid-what-is-name-and-namespace)\n\nRecap ([ref6](https://stackoverflow.com/questions/10867405/generating-v5-uuid-what-is-name-and-namespace))\n\n![](assets/uuid_recap.png)\n\n---\n\n優點：\n\n1. 簡單，不用考慮伺服器間的同步問題，且離線時也能使用\n2. 承上，高擴展性\n\n缺點：\n\n1. 128 bits 太長，浪費空間且不符合一開始的需求（64 bits）\n2. ID 不隨著時間嚴格遞增\n3. ID 內有非數字的值，不符合一開始的需求（需全為數字）\n\n### Ticket Server\n\n![](assets/ticket_server.png)\n\n如圖，ID 的發放統一由ㄧ伺服器負責\n\n優點：\n\n1. 可達成 ID 需為全數字的需求\n2. 容易實作，適用於小至中型系統\n\n缺點：\n\n1. Single point of failure\n2. 離線時無法使用\n\n### Twitter snowflake approach\n\n![](assets/snowflake.png)\n\n將 64 bits 分成幾個區塊，有點像是網路封包 header 的做法\n\n- 符號 bit：1 bit，二進位中 0 代表正，1 代表負\n\n- 時間戳記：41 bits，將毫秒等級的 unix timestamp 轉為二進位，此方式可用到 2039 年 41 bits 才會不夠用\n\n- 資料中心 ID：5 bits，上限 2 ^ 5 = 32 個資料中心\n\n- 機器 ID：5 bits，一個資料中心上限 2 ^ 5 = 32 台機器\n\n- 流水號：12 bits，為了處理高併發狀況，一毫秒內（因上面時間戳記的精度是毫秒）可能會同時產生一堆 UUID，因此一毫秒內產生的不同 UUID，流水號會以 + 1 的方式區分，此欄位每毫秒會重置\n\n## 步驟三：深入探討\n\n由上可知，最符合需求的是 Twitter snowflake approach，因此我們來探討其相關細節\n\n- 符號 bit：正常情況 ID 為正數，因此基本上此 bit 都為 0\n\n- 時間戳記：上述有提到到 2039 年 41 bits 會不夠用，因此 twitter 實務上此欄位的時間是為距公司創立時經過的相對時間，如下圖：\n\n![](assets/twitter_time.png)\n\n- 資料中心 ID：基本上不會用到這麼多資料中心，因此可減少 bit 數給其他人用，或者只有單一個資料中心的情況下，可替換為 table 的編號\n\n- 機器 ID：同上，隨著自身業務情況調整 bit 數\n\n- 流水號：用了 12 bits，每毫秒可產生 2 ^ 12 = 4096 個 UUID，需求為每秒 10,000 個 UUID 而已，因此這部分的 bits 數也可以考慮挪點給別人用\n\n## 步驟四：總結\n\n延伸可討論的點：\n\n- Clock synchronization：不同的機器的 system clock 不一定會對齊，因此實務上的解法是都跟 NTP 伺服器對時\n\n- Section length tuning：如上討論過的，snowflake 方法每個欄位需要多少 bit 的取捨，減少流水號欄位的 bit 用量而多分配給 timestamp 欄位，雖會降低併發能力，但能延後時間 overflow\n\n- High availability：ID 生成器很重要，設計上需考慮好如何保證高 availability\n\n## 補充資料\n\n一個簡單生成可排序的分散式 global uuid 演算法 [xid](https://github.com/rs/xid)\n\n一個 xid 的範例：_9m4e2mr0ui3e8a215n4g_，可以看到比 UUID 簡潔多了（雖然時間精度只到秒）\n\n其是基於 Mongo Object ID algorithm 生成的字串，Mongo Object ID 基本上格式如下：\n\n```\n0|1|2|3     4|5|6    7|8|      9|10|11\n\nTimestamp  machine   PID   Increment counter\n```\n\n再經由 base32hex (base32 的 variant 版本) 來去把它編碼成更短的字串（24 vs 20 hexadecimal digits）([ref](https://github.com/rs/xid/blob/master/README.md))\n\n![](assets/xid.png)\n\n![](assets/xid_note.png)\n\n![](assets/benchmark.png)\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/chapter-8/chapter_8/","title":"第八章：設計短網址生成器"},"frontmatter":{"draft":false},"rawBody":"# 第八章：設計短網址生成器\n\n## 前言\n\n本篇會介紹如何設計一短網址生成器，主要探討 hash 映射函數的設計（for URL shortening）以及從短網址拿到完整網址後的 URL 重導向（redirecting）\n\n## 步驟一：需求範圍確認\n\nQ: 可以舉個例子說明此短網址服務的運作嗎\n\nA: 假設 https://www.systeminterview.com/q=chatsystem&c=loggedin&v=v3&l=long 為原始網址，此服務會創建一縮短版本（alias），如 https://tinyurl.com/y7keocwj ，如點擊此 alias，會將你重導向至原始網址\n\nQ: 服務要支援多大流量規模\n\nA: 每天 100 million 個網址\n\nQ: 短網址長度是否有限制\n\nA: 越短越好\n\nQ: 生成的短網址是否有符號限制\n\nA: 需全為數字或英文（0-9 & a-z & A-Z）\n\nQ: 短網址是否可被刪除或更新\n\nA: 可假設不會被刪除或更新\n\n### 需求總結\n\n1. URL shortening：給一長網址 -> 回傳短網址\n2. URL redirecting：給一短網址 -> 回傳長網址並重導向\n3. 高可用性、擴展性、錯誤容許\n\n### 系統規格估算\n\n- 寫入量：100 million 個網址 / 日\n\n- 每秒寫入量：100 million / 24 / 3600 = 1160\n\n- 讀取量：假設讀寫比為 10 : 1，每秒讀取量為 1160 x 10 = 11,600\n\n- 假設此服務會運作 10 年，總網址量為 100 million x 365 x 10 = 365 billion\n\n- 假設平均一個網址長度為 100 bytes\n\n- 10 年的規格上限為 365 billion x 100 bytes x 10 years = 365 TB\n\n## 步驟二：high-level 架構\n\n### API Endpoints\n\n1. URL shortening\n\nREST API 範例如：\n\n```\nPOST api/v1/data/shorten\n\n- request parameter: {longUrl: longURLString}\n- return shortURL\n```\n\n假設縮短後的網址格式如：\n\n```\nwww.tinyurl.com/{hashValue}\n```\n\n我們需設計一 hash 函數來將長網址對應成短網址，需符合兩條件\n\n- 每一長網址對應唯一的短網址字串（即上面的 hashValue）\n- 每一 hashValue 可對應回去長網址\n\n2. URL redirecting\n\nREST API 範例如：\n\n```\nGET api/v1/shortUrl\n\n- Return longURL for HTTP redirection\n```\n\n重導向流程可見下圖\n\n![](assets/redirect.png)\n\n301 vs 302 重導向\n\n301 為永久轉址，302 為暫時轉址，如果想減少伺服器負擔，用 301，因為能 cache 在瀏覽器端，不會再向短網址伺服器發送請求；但如果 analytics 很重要，用 302，因為有經過短網址伺服器才能追蹤流量、分析行銷成效等等\n\n## 步驟三：深入探討\n\n### 資料結構\n\n![](assets/ds.png)\n\n### hash 函數（for URL shortening）\n\n選擇合適的 hash 函數前，我們需要先估算 hashValue 的最小長度，每一 hashValue 裡的字元可為 [0-9, a-z, A-Z]，有 10 + 26 + 26 = 62 個選項，因上限的總網址量為 365 billion 筆，hashValue 的最小長度為 minimum n that can make 62^n ≥ 365 billion，可算出 n = 7 時可符合條件，因此 hashValue 的最小長度為 7\n\n兩種設計 hash 函數的方法：\n\n1. 使用知名的 hash functions + 碰撞處理\n2. Base 62 conversion\n\n#### 知名 hash functions + 碰撞處理\n\n![](assets/hash_with_collision.png)\n\n用知名的 hash 演算法，如 CRC32、MD5、SHA-1...，缺點為 hash 出來的字串太長，以及還需要向資料庫確認是否有碰撞，會降低效能，一個提高檢查效率的改進方式為應用 Bloom filter（見下方備註），雖有可能產生 false positive，但在此應用情境下可容忍\n\n_註：Bloom filter 介紹_\n\n為了確認資料是否重複，可以用以下幾種方式：\n\n1. 直接把資料丟到資料庫，由資料庫執行去重 (Deduplication)\n2. 開一個夠大的 hash table，把資料丟進去看是否已存在\n3. 建一個 bit array，將資料由一個 hash function 映射出一 unsigned int，將該數字作為 bit array 的 index 並填入 1\n\n方法 1 在資料量很大時會嚴重拖垮資料庫效能，且每多一筆資料就要查詢一次資料庫太浪費\n\n方法 2 在資料量很大時會很耗費記憶體空間\n\n方法 3 可能會有 hash collision 問題\n\n由上可知方法 1, 2 不適用資料量大時的情境，我們可以改良方法 3，既然一個 hash function 可能會有 collision，那我們就多加幾個 hash function 產生多個 unsigned int index，若一資料全部對應的 bit array index 的值不都為 1，則他一定不存在（definitely no）；若都為 1，因為有可能是其他資料貢獻的，所以可能存在（probably yes），此即為 bloom filter 的核心概念\n\n簡易範例\n\n![](assets/bf_example.png)\n\nBloom filter 說沒有該資料的話**一定**沒有，說有該資料的話**不一定**有（definitely no and probably yes）\n\n適用情境\n\n![](assets/bf.png)\n\n使用案例（_允許些微出錯的可能性，不一定要 100% 準確_）\n\n1. Database\n\n利用 Bloom Filter 來初篩該資料是否存在於某個 Partition\n\n![](assets/bf_case1.png)\n\n2. CDN\n\nAkamai cdn 上有 75% 的網址只被訪問過一次，這種冷門的網址不需收錄進去 cdn 節省空間，也因此降低快取的負擔、提高 cache hit 機率\n\n![](assets/bf_case2.png)\n\n3. 惡意網址檢測\n\n![](assets/bf_case3.png)\n\n4. 弱密碼檢測\n\n![](assets/bf_case4.png)\n\n[Bytebytego](https://www.youtube.com/watch?v=V3pzxngeLqw)\n\nbloom filter 設計上要考慮的問題有：如何決定 bit array 大小（bit 數）、要幾個 hash functions、事先要有多少數據用以初始化 bit array、可容許的誤判率是多少...\n\n數學公式可參考 [ref](https://zhuanlan.zhihu.com/p/140545941)\n\n---\n\n上方著重在依照現有數據建立好一 bit array 後進行高效、可容許些微錯誤的查詢，但該設計方法無法刪除資料，因為可能會動到其他數據的結果，因此一個改良的方法是 bit array 的每一個值變成 counter（如下圖），當今天要刪除某數據時，直接把對應的 index 們 counter -= 1，這樣如果某 index 的值被扣到 0，那代表有被映射到該 index 的數據一定不存在，這種改良法稱為 Counting Bloom Filter\n\n缺點是儲存空間需求增加，原本 bit array 每一位只需要 1 bit，現在換成 counter，假設用 int 的話是 4 bytes，儲存空間需求直接 \\* 32\n\n![](assets/cbf.png)\n[source](https://cloud.tencent.com/developer/article/1136056)\n\n---\n\n#### Base 62 conversion\n\n![](assets/base62.png)\n\n先根據章節 7 的唯一 ID 生成器生出純數字 UUID 後，將之轉為 62 進位，如得到的 UUID 為 11,157，對應的 62 進位算法為：\n\n![](assets/base62_example.png)\n\n兩個方法的比較表\n\n![](assets/comparison.png)\n\n### URL 重導向（redirecting）\n\n![](assets/redirect_flow.png)\n\n## 步驟四：總結\n\n延伸可討論的點：\n\n- Rate limiter：避免惡意使用者灌爆服務，見第四章筆記\n\n- Web server scaling：因為此服務不需紀錄狀態，所以 web server 可輕易 auto-scale\n\n- Database scaling：Database replication and sharding\n\n- Analytics：結合分析工具來收集點擊量、何時點擊、轉化率等等商業面需要知道的數據，除了上述提到的讓流量經過短網址伺服器時收集，加入分析工具後也會讓網址變很長（UTM tracking），這時短網址服務就更重要了\n\n- Availability, consistency, and reliability，見第一章筆記\n"},{"fields":{"slug":"/content/system-design/system-design-interview-alex-xu-volume1/chapter-10/demo/client/","title":"React + TypeScript + Vite"},"frontmatter":{"draft":false},"rawBody":"# React + TypeScript + Vite\n\nThis template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.\n\nCurrently, two official plugins are available:\n\n- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react/README.md) uses [Babel](https://babeljs.io/) for Fast Refresh\n- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh\n\n## Expanding the ESLint configuration\n\nIf you are developing a production application, we recommend updating the configuration to enable type aware lint rules:\n\n- Configure the top-level `parserOptions` property like this:\n\n```js\n   parserOptions: {\n    ecmaVersion: 'latest',\n    sourceType: 'module',\n    project: ['./tsconfig.json', './tsconfig.node.json'],\n    tsconfigRootDir: __dirname,\n   },\n```\n\n- Replace `plugin:@typescript-eslint/recommended` to `plugin:@typescript-eslint/recommended-type-checked` or `plugin:@typescript-eslint/strict-type-checked`\n- Optionally add `plugin:@typescript-eslint/stylistic-type-checked`\n- Install [eslint-plugin-react](https://github.com/jsx-eslint/eslint-plugin-react) and add `plugin:react/recommended` & `plugin:react/jsx-runtime` to the `extends` list\n"},{"fields":{"slug":"/placeholder/","title":"This Is a Placeholder File for Mdx"},"frontmatter":{"draft":true},"rawBody":"---\ntitle: This Is a Placeholder File for Mdx\ndraft: true\ntags:\n  - gatsby-theme-primer-wiki-placeholder\n---\n"}]}}}